{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73db7667-facc-4719-a06c-d6c327431936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>mentioning_users/0</th>\n",
       "      <th>mentioning_users/1</th>\n",
       "      <th>mentioning_users/2</th>\n",
       "      <th>mentioning_users/3</th>\n",
       "      <th>mentioning_users/4</th>\n",
       "      <th>mentioning_users/5</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_hashtags/23</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_links/0</th>\n",
       "      <th>tweet_links/1</th>\n",
       "      <th>tweet_links/2</th>\n",
       "      <th>tweet_links/3</th>\n",
       "      <th>url</th>\n",
       "      <th>user_is_verified</th>\n",
       "      <th>user_name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Aug 20 15:11:00 +00:00 2023</td>\n",
       "      <td>Le dimanche c'est #D, comme #Destitution ???? ...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693279617707339931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/AHcCamille/status/16932796...</td>\n",
       "      <td>False</td>\n",
       "      <td>31be7426</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Aug 10 18:12:00 +00:00 2023</td>\n",
       "      <td>#propagande!! #Vaccination #gardasil</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1689701346520248320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Maren31_Uhl/status/1689701...</td>\n",
       "      <td>False</td>\n",
       "      <td>5c3a8cbb</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sat May 20 19:20:00 +00:00 2023</td>\n",
       "      <td>Learn about Gardasil HPV Vaccine Multidistrict...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660002453998190593</td>\n",
       "      <td>https://piped.video/watch?v=OkWCf0xJW0c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/WisnerBaum/status/16600024...</td>\n",
       "      <td>False</td>\n",
       "      <td>35be2b85</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Sun Aug 20 13:27:00 +00:00 2023</td>\n",
       "      <td>#Gardasil #HPV regardez les ÈlÈments du procËs...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693253363859644790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/AcGriffon/status/169325336...</td>\n",
       "      <td>False</td>\n",
       "      <td>ed75e107</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Sat Aug 12 14:25:00 +00:00 2023</td>\n",
       "      <td>Danger pour les ados ‡ la rentrÈe 2023! Le gou...</td>\n",
       "      <td>1</td>\n",
       "      <td>eee6aec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1690368947223171072</td>\n",
       "      <td>https://pgibertie.com/2023/07/13/danger-pour-l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Peck84200/status/169036894...</td>\n",
       "      <td>False</td>\n",
       "      <td>43a73a49</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       created_at  \\\n",
       "0           1  Sun Aug 20 15:11:00 +00:00 2023   \n",
       "1           2  Thu Aug 10 18:12:00 +00:00 2023   \n",
       "2           3  Sat May 20 19:20:00 +00:00 2023   \n",
       "3           6  Sun Aug 20 13:27:00 +00:00 2023   \n",
       "4           7  Sat Aug 12 14:25:00 +00:00 2023   \n",
       "\n",
       "                                           full_text  likes_count  \\\n",
       "0  Le dimanche c'est #D, comme #Destitution ???? ...           13   \n",
       "1               #propagande!! #Vaccination #gardasil            0   \n",
       "2  Learn about Gardasil HPV Vaccine Multidistrict...            3   \n",
       "3  #Gardasil #HPV regardez les ÈlÈments du procËs...            0   \n",
       "4  Danger pour les ados ‡ la rentrÈe 2023! Le gou...            1   \n",
       "\n",
       "  mentioning_users/0 mentioning_users/1 mentioning_users/2 mentioning_users/3  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           eee6aec2                NaN                NaN                NaN   \n",
       "\n",
       "  mentioning_users/4 mentioning_users/5  ... tweet_hashtags/23  \\\n",
       "0                NaN                NaN  ...               NaN   \n",
       "1                NaN                NaN  ...               NaN   \n",
       "2                NaN                NaN  ...               NaN   \n",
       "3                NaN                NaN  ...               NaN   \n",
       "4                NaN                NaN  ...               NaN   \n",
       "\n",
       "              tweet_id                                      tweet_links/0  \\\n",
       "0  1693279617707339931                                                NaN   \n",
       "1  1689701346520248320                                                NaN   \n",
       "2  1660002453998190593            https://piped.video/watch?v=OkWCf0xJW0c   \n",
       "3  1693253363859644790                                                NaN   \n",
       "4  1690368947223171072  https://pgibertie.com/2023/07/13/danger-pour-l...   \n",
       "\n",
       "  tweet_links/1 tweet_links/2 tweet_links/3  \\\n",
       "0           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN   \n",
       "\n",
       "                                                 url user_is_verified  \\\n",
       "0  https://twitter.com/AHcCamille/status/16932796...            False   \n",
       "1  https://twitter.com/Maren31_Uhl/status/1689701...            False   \n",
       "2  https://twitter.com/WisnerBaum/status/16600024...            False   \n",
       "3  https://twitter.com/AcGriffon/status/169325336...            False   \n",
       "4  https://twitter.com/Peck84200/status/169036894...            False   \n",
       "\n",
       "  user_name language  \n",
       "0  31be7426       fr  \n",
       "1  5c3a8cbb       it  \n",
       "2  35be2b85       en  \n",
       "3  ed75e107       fr  \n",
       "4  43a73a49       fr  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"processed_dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48b7ac2-3b8d-4731-a681-83615d154a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Le dimanche c'est #D, comme #Destitution ???? ...\n",
       "1                 #propagande!! #Vaccination #gardasil\n",
       "2    Learn about Gardasil HPV Vaccine Multidistrict...\n",
       "3    #Gardasil #HPV regardez les ÈlÈments du procËs...\n",
       "4    Danger pour les ados ‡ la rentrÈe 2023! Le gou...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used = data['full_text']\n",
    "data_used.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31016aac-c64a-430b-95aa-29824573f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove emails\n",
    "    text = re.sub('\\'', '', text)  # Remove apostrophes\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)  # Remove non-alphabet characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "data['preprocessed_text'] = data_used.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28308e9c-1d60-46d3-9a11-1b8200dabeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    le dimanche cest  d  comme  destitution       ...\n",
       "1                  propagande    vaccination  gardasil\n",
       "2    learn about gardasil hpv vaccine multidistrict...\n",
       "3     gardasil  hpv regardez les  l ments du proc s...\n",
       "4    danger pour les ados   la rentr e       le gou...\n",
       "Name: preprocessed_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['preprocessed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178206eb-223b-4e7c-b64d-afe9485f753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_english = data[data['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14016f25-dad0-4b52-9a75-5cd666dd8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_italian = data[data['language'] == 'it']\n",
    "data_french = data[data['language'] == 'fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811dd6bf-4bd3-41b7-9436-0d40cc6a7af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/phuonglinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/2117411335.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_english['tokens'] = data_english['preprocessed_text'].apply(tokenize)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "def tokenize(text):\n",
    "    tokens = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "data_english['tokens'] = data_english['preprocessed_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ee6d3f-5414-47b6-bec0-23cce312b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/2473408136.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_english['lemmas'] = data_english['tokens'].apply(lemmatize)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data_english['lemmas'] = data_english['tokens'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87ccb1a-24cf-4811-a2ba-b524d8eac9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(data_english['lemmas'])\n",
    "texts = data_english['lemmas']\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c352c1-cfdc-4a97-bbc8-bde800fb4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_english = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e0df00f-cda3-4a3d-85e3-7ea43968376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.049*\"s\" + 0.036*\"new\" + 0.021*\"that\" + 0.018*\"order\" + 0.015*\"woman\" + 0.014*\"tweet\" + 0.014*\"bad\" + 0.012*\"join\" + 0.012*\"las\" + 0.009*\"entire\"')\n",
      "(1, '0.047*\"video\" + 0.027*\"pipe\" + 0.027*\"take\" + 0.025*\"year\" + 0.023*\"watch\" + 0.023*\"see\" + 0.017*\"etc\" + 0.015*\"destroy\" + 0.015*\"never\" + 0.015*\"every\"')\n",
      "(2, '0.137*\"wef\" + 0.043*\"world\" + 0.026*\"say\" + 0.022*\"one\" + 0.019*\"make\" + 0.013*\"start\" + 0.011*\"china\" + 0.011*\"russia\" + 0.010*\"another\" + 0.009*\"not\"')\n",
      "(3, '0.031*\"full\" + 0.023*\"create\" + 0.021*\"support\" + 0.015*\"divide\" + 0.012*\"blackrock\" + 0.012*\"solution\" + 0.011*\"sugar\" + 0.010*\"comply\" + 0.010*\"vanguard\" + 0.009*\"yup\"')\n",
      "(4, '0.055*\"nwo\" + 0.032*\"com\" + 0.027*\"want\" + 0.021*\"diedsuddenly\" + 0.018*\"minutecities\" + 0.015*\"vaccine\" + 0.015*\"push\" + 0.015*\"gardasil\" + 0.014*\"global\" + 0.012*\"nothing\"')\n",
      "(5, '0.026*\"population\" + 0.025*\"let\" + 0.018*\"esg\" + 0.018*\"could\" + 0.018*\"australia\" + 0.015*\"puppet\" + 0.011*\"listen\" + 0.011*\"buy\" + 0.010*\"folk\" + 0.010*\"class\"')\n",
      "(6, '0.057*\"plan\" + 0.050*\"covid\" + 0.033*\"part\" + 0.025*\"need\" + 0.025*\"well\" + 0.019*\"lie\" + 0.018*\"ukraine\" + 0.018*\"happen\" + 0.016*\"work\" + 0.015*\"back\"')\n",
      "(7, '0.023*\"wake\" + 0.019*\"sdgs\" + 0.016*\"live\" + 0.015*\"news\" + 0.015*\"think\" + 0.014*\"king\" + 0.012*\"happy\" + 0.012*\"great\" + 0.011*\"town\" + 0.011*\"samaria\"')\n",
      "(8, '0.184*\"agenda\" + 0.024*\"climatescam\" + 0.016*\"greatreset\" + 0.014*\"un\" + 0.011*\"people\" + 0.011*\"like\" + 0.011*\"control\" + 0.011*\"cbdc\" + 0.010*\"newworldorder\" + 0.009*\"we\"')\n",
      "(9, '0.060*\"room\" + 0.020*\"poison\" + 0.016*\"vote\" + 0.016*\"tell\" + 0.015*\"come\" + 0.015*\"alle\" + 0.015*\"online\" + 0.013*\"accedi\" + 0.013*\"wka\" + 0.013*\"chatrooms\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model_english.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1efb3161-095e-471d-ba91-c0cc5112a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.47080604581842794\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_english, texts=data_english['lemmas'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581f393-9dca-47ed-b550-ce0063effb66",
   "metadata": {},
   "source": [
    "I have made some changes in the number of topics to identify an optimal number of topics based on the coherence score of each attempt. When the dataset is categorized into 10 topics, the coherence score increased (compared to 3 and 5). Furthermore, 10 is enough for the number of categories. Based on this standard, the number of topics in topic modelling for the next two languages will also be 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a3f05d8-0882-4f7d-a847-1d9365f253ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/4158195037.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_italian['tokens'] = data_italian['preprocessed_text'].apply(tokenize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.010*\"lecciones\" + 0.010*\"ecologismo\" + 0.010*\"rituales\" + 0.010*\"farso\" + 0.010*\"figlio\" + 0.010*\"atrazina\" + 0.010*\"satanic\" + 0.010*\"industria\" + 0.010*\"namere\" + 0.010*\"banca\"')\n",
      "(1, '0.112*\"agenda\" + 0.032*\"video\" + 0.030*\"piped\" + 0.023*\"il\" + 0.016*\"potere\" + 0.016*\"politico\" + 0.016*\"cos\" + 0.015*\"loro\" + 0.012*\"greatreset\" + 0.012*\"via\"')\n",
      "(2, '0.085*\"il\" + 0.058*\"agenda\" + 0.037*\"uno\" + 0.035*\"di\" + 0.030*\"non\" + 0.028*\"a il\" + 0.026*\"di il\" + 0.020*\"che\" + 0.018*\"essere\" + 0.017*\"avere\"')\n",
      "(3, '0.043*\"di\" + 0.024*\"stare\" + 0.024*\"Usa\" + 0.022*\"davos\" + 0.014*\"com\" + 0.014*\"vaccino\" + 0.014*\"tutto\" + 0.014*\"usare\" + 0.014*\"di il\" + 0.010*\"schwab\"')\n",
      "(4, '0.077*\"si\" + 0.036*\"agenda\" + 0.028*\"leggere\" + 0.028*\"scrivere\" + 0.019*\"con\" + 0.019*\"soros\" + 0.006*\"accoglienza\" + 0.006*\"ghetto\" + 0.006*\"liberazione\" + 0.006*\"franceriots\"')\n",
      "(5, '0.060*\"agenda\" + 0.027*\"il\" + 0.024*\"globalista\" + 0.024*\"com\" + 0.024*\"de\" + 0.022*\"france\" + 0.017*\"macrondemission\" + 0.017*\"macron\" + 0.017*\"mociondecensura\" + 0.017*\"manifestation\"')\n",
      "(6, '0.097*\"gardasil\" + 0.026*\"di il\" + 0.026*\"vaccination\" + 0.024*\"il\" + 0.023*\"casa\" + 0.022*\"wef\" + 0.020*\"Poizon\" + 0.020*\"vaccin\" + 0.019*\"agenda\" + 0.015*\"energia\"')\n",
      "(7, '0.110*\"gardasil\" + 0.041*\"da il\" + 0.040*\"son\" + 0.033*\"poi\" + 0.026*\"governo\" + 0.022*\"agendare\" + 0.019*\"agendo\" + 0.011*\"seguire\" + 0.011*\"Wef\" + 0.011*\"strategia\"')\n",
      "(8, '0.028*\"il\" + 0.022*\"live\" + 0.022*\"novax\" + 0.013*\"agendere\" + 0.013*\"nwo\" + 0.013*\"tutto\" + 0.012*\"gardasil\" + 0.011*\"ora\" + 0.009*\"ficco\" + 0.009*\"culo\"')\n",
      "(9, '0.040*\"agenda\" + 0.027*\"Russia\" + 0.023*\"rinnovabile\" + 0.023*\"sustainability\" + 0.023*\"energia\" + 0.021*\"energy\" + 0.017*\"pi\" + 0.017*\"europe\" + 0.013*\"di\" + 0.013*\"elettricit\"')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/4158195037.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_italian['lemmas'] = data_italian['tokens'].apply(lemmatize)\n"
     ]
    }
   ],
   "source": [
    "data_italian['tokens'] = data_italian['preprocessed_text'].apply(tokenize)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('it_core_news_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data_italian['lemmas'] = data_italian['tokens'].apply(lemmatize)\n",
    "id2word = corpora.Dictionary(data_italian['lemmas'])\n",
    "texts = data_italian['lemmas']\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model_italian = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "topics = lda_model_italian.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba621a48-bed5-4b0a-9e2c-e50f647442cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.45179699013097335\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_italian, texts=data_italian['lemmas'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2964186-de62-4e38-a0f7-498028ccc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/3955827841.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_french['tokens'] = data_french['preprocessed_text'].apply(tokenize)\n",
      "/var/folders/v_/tpg1b9n963d1g2mphq6zhp000000gn/T/ipykernel_86081/3955827841.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_french['lemmas'] = data_french['tokens'].apply(lemmatize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.030*\"sant\" + 0.021*\"celui\" + 0.017*\"comment\" + 0.017*\"votre\" + 0.014*\"gardasil\" + 0.012*\"minute\" + 0.012*\"org\" + 0.012*\"ministre\" + 0.011*\"cancer\" + 0.011*\"mentir\"')\n",
      "(1, '0.071*\"le\" + 0.044*\"de\" + 0.031*\"pas\" + 0.026*\"être\" + 0.021*\"il\" + 0.020*\"que\" + 0.020*\"avoir\" + 0.019*\"un\" + 0.019*\"ce\" + 0.017*\"gardasil\"')\n",
      "(2, '0.088*\"le\" + 0.034*\"nouveau\" + 0.031*\"inefficace\" + 0.025*\"vaccin\" + 0.024*\"dangereux\" + 0.023*\"gardasil\" + 0.022*\"contre\" + 0.021*\"com\" + 0.021*\"ado\" + 0.021*\"danger\"')\n",
      "(3, '0.030*\"odd\" + 0.026*\"le\" + 0.022*\"temps\" + 0.020*\"agender\" + 0.015*\"autre\" + 0.012*\"tre\" + 0.011*\"agenda\" + 0.010*\"raoult\" + 0.009*\"tr\" + 0.009*\"être\"')\n",
      "(4, '0.014*\"sident\" + 0.013*\"promotion\" + 0.013*\"plainte\" + 0.012*\"pharmaceutique\" + 0.011*\"donn\" + 0.008*\"ind\" + 0.008*\"er\" + 0.008*\"merck\" + 0.008*\"lhumanit\" + 0.008*\"base\"')\n",
      "(5, '0.098*\"de\" + 0.097*\"le\" + 0.043*\"gardasil\" + 0.030*\"un\" + 0.026*\"et\" + 0.023*\"pour\" + 0.022*\"être\" + 0.020*\"en\" + 0.013*\"vaccin\" + 0.012*\"il\"')\n",
      "(6, '0.026*\"falloir\" + 0.022*\"agenda\" + 0.015*\"injecter\" + 0.014*\"jour\" + 0.011*\"travail\" + 0.011*\"passer\" + 0.010*\"sou\" + 0.010*\"sans\" + 0.010*\"population\" + 0.009*\"celer\"')\n",
      "(7, '0.033*\"video\" + 0.031*\"piped\" + 0.014*\"odd\" + 0.014*\"moignage\" + 0.012*\"ici\" + 0.011*\"attali\" + 0.010*\"organisation\" + 0.009*\"changement\" + 0.008*\"agenda\" + 0.007*\"ong\"')\n",
      "(8, '0.056*\"ni\" + 0.030*\"on\" + 0.028*\"gar\" + 0.027*\"fille\" + 0.017*\"vacciner\" + 0.015*\"tribu\" + 0.015*\"opinion\" + 0.014*\"dr\" + 0.011*\"cancer\" + 0.008*\"rard\"')\n",
      "(9, '0.066*\"le\" + 0.036*\"de\" + 0.032*\"effet\" + 0.029*\"secondaire\" + 0.028*\"et\" + 0.020*\"pour\" + 0.019*\"gardasil\" + 0.018*\"grave\" + 0.017*\"vaccin\" + 0.016*\"par\"')\n"
     ]
    }
   ],
   "source": [
    "data_french['tokens'] = data_french['preprocessed_text'].apply(tokenize)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('fr_core_news_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data_french['lemmas'] = data_french['tokens'].apply(lemmatize)\n",
    "id2word = corpora.Dictionary(data_french['lemmas'])\n",
    "texts = data_french['lemmas']\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model_french = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "topics = lda_model_french.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4045d532-0b1c-4756-9f16-1d2c445d3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4625807249433322\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_french, texts=data_french['lemmas'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06157f-01f0-41b1-b4cd-3355dcaeaa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
