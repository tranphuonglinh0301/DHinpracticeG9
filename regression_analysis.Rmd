---
title: "Regression analysis"
output: html_document
date: "2025-01-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```

```{r}
data <- read.csv("processed_dataset.csv")
```

```{r}
# Create a new column for the engagement matrix
data$engagement <- data$likes_count + data$played_count + data$quotes_count + data$replies_count + data$retweets_count
# Convert 'language' to categorical variables
data$language <- as.factor(data$language)
```

```{r}
model <- lm(engagement ~ language, data)
summary(model)
```
- In the coefficients table, the 'Estimate' column shows the average engagement for each language. The intercept represents the baseline category, so English tweets have an average engagement at 10.69. French tweets' engagement is 29.75 higher than English ones on average, while Italian tweets' engagement is similar to English ones, with only 0.44 higher relative to English ones. 

- Significance can be told from p-values. A p-value smaller than 0.05 typically suggests that there is a strong evidence that the x-variable influences the y-variable. Here, tweets in French have a significant impact on engagement compared to English tweets. On the other hand, engagement of tweets in Italian do not differ significantly from English ones.

- The multiple R-squared indicates that only about 1.8% of the variation in engagement is explained by the language. Thus, other factors can play more significant roles and need to be considered, such as the content.

```{r}
cor(data[, c("likes_count", "played_count", "quotes_count", "replies_count", "retweets_count", "engagement")])
```
```{r}
ggplot(data, aes(language, engagement)) +
  geom_boxplot() +
  scale_x_discrete(labels = c("English", "French", "Italian")) +
  labs(x = "Language", y = "Engagement per tweet",
       title = "The distribution of each tweetâ€™s engagement by language") +
  theme_classic()
```
This plot demonstrates that the data points are extremely skewed and have a few outliers, so a standard linear regression is actually not suitable in this case because of heterogeneity and the non-normal distribution.

```{r}
library(MASS)
model_robust <- rlm(engagement ~ language, data)
summary(model_robust)
```
Using the robust linear regression accounts for extreme values. Now, the engagement level for tweets in English (the reference group) is 1.96. Tweets in French have approximately 1.06 units higher engagement than the English ones. Given that the t-value is about 6.6, it is statistically significant. In contrast, the engagement for tweets in Italian is around 0.22 units lower than English ones. However, it is statistically insignificant. In addition, a much smaller RSE at 2.919 compared to 93.7 for the standard measure shows that this model is a better fit. 


```{r}
model_nb <- glm.nb(engagement ~ language, data)
summary(model_nb)
```
An alternative method is the negative binomial regression. It considers over-dispersed data and discrete variables. x-variable is regressed on the natural logarithm of the y-variable, so the intercept indicates that the mean engagement count for tweets in English is about e^2.37 = 10.69. The other two coefficients represent the additional effect relative to the baseline language. Hence, the average engagement count for tweets in French is approximately e^1.33 = 3.77 times higher. The extremely small p-value shows that this result is significant. Yet, the tweets in Italian have only e^0.04 = 1.04 times higher engagement in average, and the coefficient is not significant. 
(Reference: https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/)

Overall, the statistical tests above all demonstrate that given the reference language as English, tweets in French have a statistically significant 3.77 times higher engagement. Tweets in Italian have more or less the same level of engagement as English ones, but this result is statistically insignificant. 

```{r}
write.csv(data, "dataset_engagement.csv", row.names = FALSE)
```

